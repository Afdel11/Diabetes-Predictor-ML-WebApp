# -*- coding: utf-8 -*-
"""Diabet_Clas_Log_Reg_SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FfWHk_WgAFa1LbYRQA22Um0nm67MGlqA
"""

# Importer les packages

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# Supprimer les warning
import warnings
warnings.filterwarnings("ignore")

"""### <font color = 'teal'>Importer et Lire les donn√©es<font>"""

from google.colab import drive
drive.mount('/content/drive')

# importer les donn√©es
df = pd.read_csv('/content/drive/MyDrive/MES COURS/L3/MACHINE LEARNING/ML Final Projet/diabetes.csv')
df.head()

# dimension des donn√©es
df.shape

# infos des donn√©es
df.info()

"""### <font color = 'teal'>Exploration et preparation des donn√©es<font>

###### <font color = 'bisque'> Selection des variables cat√©gorielles et quantitatives
"""

# # selection les variables cat√©gorielles
# cat_data = df.select_dtypes(include = 'object')

# selection des variables quantitatives
quant_data = df.select_dtypes(include = 'number')
quant_data.head()

"""###### <font color = 'bisque'> Exploration des variables cat√©gorielles"""

# # d√©crire les variables cat√©gorielles
# cat_data.describe(include = 'object')

# Diagrammes en barre des variables cat√©gorielles
# for col in cat_data.columns:
#     val_count = cat_data[col].value_counts()
#     fig = px.bar(x = val_count.index, y= val_count.values, color = val_count.index )
#     fig.show()

"""###### <font color = 'bisque'> Exploration des variables quantitatives"""

# d√©crire les variables quantitatives
quant_data.describe(include= 'number')

# pairplot des variables quantitatives
sns.pairplot(quant_data)

# boxplots des variables quantitatives
for col in quant_data.columns:
    fig = px.box(quant_data, x = col)
    fig.show()

"""###### <font color = 'bisque'> Preparation des donn√©es"""

# G√©rer les doublons
doublons = df.duplicated().sum()
doublons

# G√©rer les valeurs ab√©rrantes des variables quantitatives
k = 9 # Dans la litt√©rature k = 1.5 est plus utilis√©
for col in quant_data.columns:
  Q1 = df[col].quantile(0.25) # premier quartile
  Q3 = df[col].quantile(0.75) # troisi√®me quartile
  IQR = Q3 - Q1 # l'√©cart interquartile
  min_value  = Q1 -  k * IQR # valeur minimale
  max_value = Q3 +  k * IQR # valeur maximale
  df = df[(df[col] >= min_value) & (df[col] <= max_value)] # slicing
  df = df.reset_index(drop = True) # reset des index

# # Encoder les variables cat√©gorielles
# from sklearn.preprocessing import LabelEncoder
# encoder = LabelEncoder()
# for col in cat_data.columns:
#   df[col] = encoder.fit_transform(df[col])

# df.head()

# Fractionner les donn√©es en variables pr√©dicteurs (x) et variable cibel(y)
x = df.drop('Outcome', axis = 1).values
y = df.Outcome.values
x, y

# normaliser les donn√©es
from sklearn.preprocessing import StandardScaler

x = StandardScaler().fit_transform(x)

# splitter les donn√©es en train, val et test
# train (80%), val(10%) et test(10%)
#train : donn√©es d'entrainement, val: donn√©es utiliser pour √©valuer chaque et test: donn√©es pour tester le mod√®le le plus performant


from sklearn.model_selection import train_test_split
x_train, x_vt, y_train, y_vt = train_test_split(x, y, test_size = 0.2, random_state = 42) #split en 80 et 20 %

x_test, x_val, y_test, y_val = train_test_split(x_vt, y_vt, test_size = 0.5, random_state = 42) #split 50,50

"""### <font color = 'teal'>KNN<font>

###### <font color = 'bisque'> Recherche des param√®tres optimaux
"""

from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
# dictionnaire params
params={"n_neighbors": np.arange(2,11)}
# instantier le mod√®le Logistic regression
knn = KNeighborsClassifier()
# instantier le mod√®le gridsearch
grid=GridSearchCV(knn,params,cv=5)
# lancer la recherche
grid.fit(x_train,y_train)

# k optimal
best_k = grid.best_params_
best_k

grid.best_score_

"""###### <font color = 'bisque'> Entrainement du mod√®le"""

# Entrainer le mod√®le avec le k optimal = 6
knn = KNeighborsClassifier(n_neighbors = 6)
# entrainement du model
knn.fit(x_train, y_train)

# sauvegarder le model knn
import joblib
joblib.dump(knn, 'knn_model.pkl')

"""###### <font color = 'bisque'> Evaluation du mod√®le"""

# Accuracy et F1 score du mod√®le sur les donn√©es de validation
from sklearn.metrics import accuracy_score, f1_score
y_pred = knn.predict(x_val)
#calcul de l'accuracy score et f1 score
print(f'Accuracy score: {round(accuracy_score(y_pred,y_val),3)}')
print(f'F1 score: {round(f1_score( y_pred,y_val, average="micro"),3)}')

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# üîπ Fonction pour afficher la matrice de confusion
def CM_visualisation(model_objet, x_val, y_val):
    # Pr√©dictions du mod√®le
    y_pred = model_objet.predict(x_val)

    # Matrice de confusion
    cnf_matr = confusion_matrix(y_val, y_pred, labels=[0, 1])

    # Affichage avec ConfusionMatrixDisplay
    disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matr, display_labels=['Non-Diab√©tique', 'Diab√©tique'])
    disp.plot(cmap="Blues")

    # Ajouter un titre
    plt.title('Matrice de Confusion - Pr√©diction du Diab√®te')
    plt.show()

# matrice de confusion
# Appel correct avec X_val et y_val
CM_visualisation(knn, x_val, y_val)

print(x_val)
print(y_val)

"""### <font color = 'teal'>Logistic Regression<font>

###### <font color = 'bisque'> Recherche des param√®tre optimaux
"""

# Recherche des param√®tres optimaux pour la logistic regression
from sklearn.linear_model import LogisticRegression
# dictionnaire params
params={"C":np.logspace(-3,3,7),"penalty": ['l1','l2']}
# instantier le mod√®le Logistic regression
lg=LogisticRegression()
# instantier le mod√®le gridsearch
grid=GridSearchCV(lg,params,cv=5)
# lancer la recherche
grid.fit(x_train,y_train)

# Afficher les param√®tres optimaux
grid.best_params_

"""###### <font color = 'bisque'> Entrainement du mod√®le"""

# Entrainer la logistic regression en utilisant les param√®tres optimaux
lg = LogisticRegression(C = 0.1, penalty = 'l2')
# entrainement du model
lg.fit(x_train, y_train)

"""###### <font color ='bisque'>Evaluation du mod√®le"""

# sauvegarder le model Log_reg
import joblib
joblib.dump(lg, 'log_reg_model.pkl')

# Accuracy et F1 score du mod√®le sur les donn√©es de validation
from sklearn.metrics import accuracy_score, f1_score
y_pred = lg.predict(x_val)
#calcul de l'accuracy score et f
print(f'Accuracy score: {round(accuracy_score(y_pred,y_val),3)}')
print(f'F1 score: {round(f1_score( y_pred,y_val, average="micro"),3)}')

# Matrice de confusion
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Fonction pour afficher la matrice de confusion
def CM_visualisation(model_objet, x_val, y_val):
    # Pr√©dictions du
    y_pred = model_objet.predict(x_val)

    # Matrice de confusion
    cnf_matr = confusion_matrix(y_val, y_pred, labels=[0, 1])

    # Affichage avec ConfusionMatrixDisplay
    disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matr, display_labels=['Non-Diab√©tique', 'Diab√©tique'])
    disp.plot(cmap="Greens")
    # Ajouter un titre
    plt.title('Matrice de Confusion - Pr√©diction du Diab√®te')
    plt.show()

# matrice de confusion
# Appel correct avec X_val et y_val
CM_visualisation(lg, x_val, y_val)

"""### <font color = 'teal'>Support Vectors Machines (SVM)<font>

###### <font color = 'bisque'> Recherche des param√®tre optimaux
"""

# Recherche des param√®tres optimaux pour le svm
from sklearn.svm import SVC
# dictionnaire des params
param_ = {'C':np.logspace(-1,3,5), 'kernel':['linear','rbf']}
# instantier le mod√®le svm
svm = SVC()
# instantier le mod√®le gridsearch
grid_ = GridSearchCV(svm, param_, cv =5)
# entrainer le mod√®le
grid_.fit(x_train, y_train)

# afficher les param√®tres optimaux
grid_.best_params_

"""###### <font color = 'bisque'> Entrainement du mod√®le"""

# Entrainer svm en utilisant les param√®tres optimaux, C = 1000, kernel ='rbf'
svm = SVC(C = 1.00, kernel ='rbf')
# entrainement du model
svm.fit(x_train, y_train)

# sauvegarder le model svm
import joblib
joblib.dump(svm, 'svm_model.pkl')

"""###### <font color ='bisque'>Evaluation du mod√®le<font>"""

# tester le model le plus performant
from sklearn.metrics import accuracy_score, f1_score
y_pred = svm.predict(x_test)
#calcul de l'accuracy score et f1
print(f'Accuracy score: {round(accuracy_score(y_pred,y_test),3)}')
print(f'F1 score: {round(f1_score( y_pred,y_test, average="micro"),3)}')

# Matrice de confusion
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Fonction pour afficher la matrice de confusion
def CM_visualisation(model_objet, x_val, y_val):
    # Pr√©dictions du mod√®le
    y_pred = svm.predict(x_val)
    model_objet.predict(x_val)

    # Matrice de confusion
    cnf_matr = confusion_matrix(y_val, y_pred, labels=[0, 1])

    # Affichage avec ConfusionMatrixDisplay
    disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matr, display_labels=['Non-Diab√©tique', 'Diab√©tique'])
    disp.plot(cmap="Oranges")
    # Ajouter un titre
    plt.title('Matrice de Confusion - Pr√©diction du Diab√®te')
    plt.show()

# matrice de confusion
# Appel correct avec X_val et y_val
CM_visualisation(svm, x_val, y_val)

"""### <font color ='bisque'>Tester le mod√®le le plus performant<font>"""

# tester le model le plus performant
from sklearn.metrics import accuracy_score, f1_score
y_pred = svm.predict(x_test)
#calcul de l'accuracy score et f1
print(f'Accuracy score: {round(accuracy_score(y_pred,y_test),3)}')
print(f'F1 score: {round(f1_score( y_pred,y_test, average="micro"),3)}')

